<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Ihor Omelchenko Blog</title><link href="https://ihoromi4.github.io/" rel="alternate"></link><link href="https://ihoromi4.github.io/feeds/all.atom.xml" rel="self"></link><id>https://ihoromi4.github.io/</id><updated>2023-09-02T14:00:00+03:00</updated><subtitle>Python | C/C++ | Data Scientist | ML Developer</subtitle><entry><title>Про навчання з підкріпленням</title><link href="https://ihoromi4.github.io/pro-navchannia-z-pidkriplenniam-ua.html" rel="alternate"></link><published>2023-09-02T14:00:00+03:00</published><updated>2023-09-02T14:00:00+03:00</updated><author><name>Ihor Omelchenko</name></author><id>tag:ihoromi4.github.io,2023-09-02:/pro-navchannia-z-pidkriplenniam-ua.html</id><summary type="html">&lt;p&gt;Навчання з підкріпленням - це напрямок штучного інтелекту, який спрямований на розвиток алгоритмів та моделей, здатних самостійно вчитися та приймати рішення на основі взаємодії з навколишнім середовищем. &lt;/p&gt;
&lt;p&gt;Основна ідея полягає в тому, щоб створити агентів, які можуть взаємодіяти з навколишнім світом, отримувати відгуки у вигляді підкріплення або покарання і вдосконалювати свої …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Навчання з підкріпленням - це напрямок штучного інтелекту, який спрямований на розвиток алгоритмів та моделей, здатних самостійно вчитися та приймати рішення на основі взаємодії з навколишнім середовищем. &lt;/p&gt;
&lt;p&gt;Основна ідея полягає в тому, щоб створити агентів, які можуть взаємодіяти з навколишнім світом, отримувати відгуки у вигляді підкріплення або покарання і вдосконалювати свої дії, максимізуючи нагороду. Навчання з підкріпленням є ключовим компонентом для створення інтелігентних систем, які можуть досягати високих результатів у завданнях без заздалегідь заданого алгоритму.&lt;/p&gt;
&lt;h1&gt;Три види навчання&lt;/h1&gt;
&lt;p&gt;В момент написання цієї статті домінуючим підходом у штучному інтелекті є методи, що вчаться. Їх окреми яскравий представник - глибокі нейронні мережі. Такі алгоритми здатні знаходити алгоритм за набором прикладів.&lt;/p&gt;
&lt;p&gt;Перша нейромережева модель природнього нейрону з'явилася у далекому 1942 році[1].  &lt;/p&gt;
&lt;p&gt;Традиційно методи машинного навчання поділяють на три великі групи:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Навчання з учителем (англ. Supervised Learning, SL)&lt;/li&gt;
&lt;li&gt;Навчання без вчителя (англ. Unsupervised Learning, UL)&lt;/li&gt;
&lt;li&gt;Навчання з підкріпленням (англ. Reinforcement Learning, RL)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Навчання з учителем об'єднує підходи основна ціль яких - узагальнення навчальних даних. &lt;/p&gt;
&lt;p&gt;Методи "навчання без вчителя" вирішують проблему стискання даних шляхом знаходження внутрішньої структури.&lt;/p&gt;
&lt;p&gt;Навчання з підкріпленням вивчає як агенту навчитися діяти у середовищі оптимально.&lt;/p&gt;
&lt;h1&gt;Коротка історія навчання з підкріпленням&lt;/h1&gt;
&lt;p&gt;Навчання з підкріпленням виникло з двох паралельних віток досліджень[2], які розвивалися майже незалежно.&lt;/p&gt;
&lt;p&gt;Перша виникла з досліджень поведінки тварин та вивчала навчання шляхом спроб та помилок.&lt;/p&gt;
&lt;p&gt;Друга вітка походила з теорії оптимального управління. Термін "оптимальне управління" почав вживатися у 1950-х. Цей підхід працював з функціями цінності, динамічним програмуванням та, більшою мірою, не допускав навчання.&lt;/p&gt;
&lt;p&gt;Також можна виділити третій підхід, заснований на часових різницях (англ. temporal-difference).&lt;/p&gt;
&lt;p&gt;Сучасне навчання з підкіпленням виникло в 1980-х шляхом об'єднаня трьох вище згаданих віток в одну.&lt;/p&gt;
&lt;h1&gt;Особливості навчання з підкріпленням&lt;/h1&gt;
&lt;p&gt;На відміну від інших підходів, навчання з підкріпленням працює з послідовним прийняттям рішень, не потребує заздалегіть відомої моделі середовища.
Навчання з підкріпленням породжує проблеми які не можна знайти у навчанні з вчителем чи навчанні без вчителя. Коли ми починаємо вирішувати задачу навчання з підкріпленням, ми не маємо готового датасету для навчання, натомість агент збирає дані в процесі взаємодії з середовищем. Агент сам збирає датасет для навчання.&lt;/p&gt;
&lt;h1&gt;Формалізм навчання з підкріпленням&lt;/h1&gt;
&lt;p&gt;Головним формалізмом в навчанні з підкріпленням є &lt;a href="https://en.wikipedia.org/wiki/Markov_decision_process"&gt;Марківський процес прийняття рішень&lt;/a&gt;. Це загальний спосіб описати стохастичний процес з дискретним часом у якому дії агента впливають на динаміку середовища.&lt;/p&gt;
&lt;p&gt;Головні складові навчання з підкріпленням:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Середовище (англ. Environment): все, окрім агента&lt;/li&gt;
&lt;li&gt;Агент (англ. Agent): сутність, що здатна спостерігати середовище, та обирати дії.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Для кожної системи вибір межі розділу між середовищем та агентом дещо довільний. Наприклад, у ситуації водій-автомобіль-шосе, можливо декілька представлень. Перший варіант: водій це агент, який управляє автомобілем. Інший - автомобіль з водієм це агент, який їде по шосе.&lt;/p&gt;
&lt;p&gt;Основні поняття MDP:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Стан &lt;span class="math"&gt;\(s_t\)&lt;/span&gt;: вкожен момент часу &lt;span class="math"&gt;\(t\)&lt;/span&gt; середовище перебуває у певному стані &lt;span class="math"&gt;\(s_t\)&lt;/span&gt;. Конкретне представлення стану зележить від середовища. Зазвичай це вектор, або матриця.&lt;/li&gt;
&lt;li&gt;Дія &lt;span class="math"&gt;\(a_t\)&lt;/span&gt;: в кожен момент часу &lt;span class="math"&gt;\(t\)&lt;/span&gt; агент може обрати одну можливу дію з набору, який визначає середовище.&lt;/li&gt;
&lt;li&gt;Нагорода &lt;span class="math"&gt;\(r_t\)&lt;/span&gt;: після виконання дії агент отримує від середовища нагороду. Особливість навчання з підкіпленням в тому, що ця нагорода не обов'язково пов'язана з попередньою дією, вона може бути наслідком будь-якої дії що була обрана в минулому.&lt;/li&gt;
&lt;li&gt;Функція нагороди &lt;span class="math"&gt;\(R(s_t, s_{t+1})\)&lt;/span&gt;: функція, яка визначає яку саме чисельну нагороду отримає агент перейшовши з стану &lt;span class="math"&gt;\(s_t\)&lt;/span&gt; до стану &lt;span class="math"&gt;\(s_{t+1}\)&lt;/span&gt;.&lt;/li&gt;
&lt;li&gt;Функція переходу &lt;span class="math"&gt;\(P(s_t, a_t, s_{t+1})\)&lt;/span&gt;: це розподіл імовірностей переходів між станами при обраних діях.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Формально цей формалізм застосовний лише для опису систем, для яких виконується марківське припущення, іншими словами середовище має &lt;a href="https://uk.wikipedia.org/wiki/%D0%9C%D0%B0%D1%80%D0%BA%D0%BE%D0%B2%D1%81%D1%8C%D0%BA%D0%B0_%D0%B2%D0%BB%D0%B0%D1%81%D1%82%D0%B8%D0%B2%D1%96%D1%81%D1%82%D1%8C"&gt;марковську властивість&lt;/a&gt;. Це можна пояснити як відсутність пам'яті у стохастичному процесі. Іншими словами, все що потрібно знати агенту для оптимальної поведінки міститься в останному стані середовища &lt;span class="math"&gt;\(s_t\)&lt;/span&gt;, а всі попередні стани не потрібні. Формально це можна записати як незалежність умовного статистичного розподілу від попередніх станів, кріп останнього:
&lt;/p&gt;
&lt;div class="math"&gt;$$P(s_{t+1}| s_{t}) = P(s_{t+1} | s_t, s_{t-1}, ..., s_2, s_1)$$&lt;/div&gt;
&lt;h1&gt;Джерела&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;McCulloch, W. S., &amp;amp; Pitts, W. (1943). A logical calculus of the ideas immanent in nervous activity. The bulletin of mathematical biophysics, 5, 115-133.&lt;/li&gt;
&lt;li&gt;Sutton, R. S., &amp;amp; Barto, A. G. (2018). Reinforcement learning: An introduction. MIT press.&lt;/li&gt;
&lt;/ol&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js','boldsymbol.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="Reinforcement Learning"></category><category term="AI"></category><category term="ML"></category><category term="RL"></category></entry><entry><title>Variational Autoencoder (VAE) Example using MNIST</title><link href="https://ihoromi4.github.io/variational-autoencoder-vae-example-using-mnist-ru.html" rel="alternate"></link><published>2021-05-18T09:20:00+03:00</published><updated>2021-05-18T09:20:00+03:00</updated><author><name>Ihor Omelchenko</name></author><id>tag:ihoromi4.github.io,2021-05-18:/variational-autoencoder-vae-example-using-mnist-ru.html</id><summary type="html">&lt;p&gt;Interactive examples of Variational Autoencoder.&lt;/p&gt;</summary><content type="html">&lt;script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"&gt;&lt;/script&gt;
&lt;script src="https://cdn.jsdelivr.net/npm/onnxjs/dist/onnx.min.js"&gt;&lt;/script&gt;
&lt;style&gt;
div.example { width: 100%; height: auto; text-align: center;}
img#map { width: 100%; float: left; display:inline-block; }
img#map:after { content: ""; display: block; padding-bottom: 100% }
canvas#viewport { width: 100%; image-rendering: crisp-edges; float: right }
canvas#draw { width: 100%; float: left; image-rendering: crisp-edges; }
canvas#restore { width: 100%; image-rendering: crisp-edges; float: right }
div.vertical { border-left: 6px solid #0000; height: 100%; position:absolute; left: 50%; }
button {
  background-color: #D9411E;
  padding: .6em .6em;
  font-size: .8em;
  line-height: 1;
  color: #ffffff;
  text-align: center;
  white-space: nowrap;
  vertical-align: baseline;
  border-radius: .25em;
}
div.border {
  display:inline-block;
  background-color: #000;
  border-radius: 10px;
  border: 4px solid #D9411E;
  padding: 5px;
  width: 100%;
}
table.example {
    text-align: center;
    vertical-align: middle;
    margin-left: auto;
    margin-right: auto;
}
th, td {
    width: 100%;
    text-align: center;
    vertical-align: middle !important;
    align-content: center;
}

.slidecontainer {
  width: 100%; /* Width of the outside container */
  padding: 6px;
}

/* The slider itself */
.slider {
  -webkit-appearance: none;  /* Override default CSS styles */
  appearance: none;
  width: 100%; /* Full-width */
  height: 25px; /* Specified height */
  background: #d3d3d3; /* Grey background */
  outline: none; /* Remove outline */
  opacity: 0.9; /* Set transparency (for mouse-over effects on hover) */
  -webkit-transition: .2s; /* 0.2 seconds transition on hover */
  transition: opacity .2s;
}

/* Mouse-over effects */
.slider:hover {
  opacity: 1; /* Fully shown on mouse-over */
}

/* The slider handle (use -webkit- (Chrome, Opera, Safari, Edge) and -moz- (Firefox) to override default look) */
.slider::-webkit-slider-thumb {
  -webkit-appearance: none; /* Override default look */
  appearance: none;
  width: 25px; /* Set a specific slider handle width */
  height: 25px; /* Slider handle height */
  background: #D9411E; /* Green background */
  cursor: pointer; /* Cursor on hover */
}

.slider::-moz-range-thumb {
  width: 25px; /* Set a specific slider handle width */
  height: 25px; /* Slider handle height */
  background: #D9411E; /* Green background */
  cursor: pointer; /* Cursor on hover */
}
&lt;/style&gt;

&lt;p&gt;Вариационный Автоенкодер (англ. Variational Autoencoder - VAE) это тип нейронной сети, который используется для нахождения способа эффективного кодирования через обучение без учителя.&lt;/p&gt;
&lt;p&gt;Вариационный автокодировщик состоит из двух нейросетей. Первая сжимает входные данные, переводя их в векторное пространство более низкой размерности чем входные данные, она называется &lt;strong&gt;кодировщик&lt;/strong&gt;. Вторая, векторы из этого пространства, восстанавливает в данные подобные исходным и называется &lt;strong&gt;декодировщик&lt;/strong&gt;. Цель обучения - наилучшим способом сжимать и восстанавливать данные, подобные данным из обучающего набора.&lt;/p&gt;
&lt;p&gt;Автокодировщики обладают двумя интересными для нас свойствами:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Способность сжимать входные данные (снижение размерности данных)&lt;/li&gt;
&lt;li&gt;Возможность генерировать новые данные из сжатого представления (генеративная модель)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Рассмотрим подробнее каждое свойство.&lt;/p&gt;
&lt;h1&gt;Данные&lt;/h1&gt;
&lt;p&gt;В данной статье используется, ставший уже классическим, датасет MNIST. Он состоит из 70 000 изображений рукописных цифр (от 0 до 9). Каждое изображение имеет разрешение 28 х 28 пикселей. Цвета представленны оттенками серого. Датасет содержит порядка 7000 примеров написания каждой цифры. Нетрудно посчитать, что каждое изображение состоит из 784 пикселей, каждый представлен одним числом uint8. И следовательно информация о том, какая из 10 цифр нарисована на изображении содержится в этих 784 числах. Очевидно, для того чтобы закодировать информацию о числе нужно намного меньше данных. Например, информация о цифре (их 10) и стиле написания цифры (наклон, масштаб и т.д.).&lt;/p&gt;
&lt;h1&gt;Сжатие данных&lt;/h1&gt;
&lt;p&gt;Начнем сразу же с примера сжатия изображения рукописной цифры. Здесь используется предварительно обученный вариационный автоенкодер. Как уже было сказано выше, изображение состоит из 784 чисел. После сжатия нейронной сетью мы получим 10 чисел. Попробуйте сами нарисовать цифру в левом прямоугольнике и она в реальном времени будет преобразована кодировщиком в код. Или задайте код набором ползунков. В правом прямоугольнике отобразится цифра восстановаленная из кода декодировщиком.&lt;/p&gt;
&lt;div class="example" id="example_2"&gt;
    &lt;table class="example" style="width: 100%; height: auto; table-layout: fixed;"&gt;
        &lt;tr&gt;
            &lt;th&gt;&lt;text&gt;Draw image here&lt;/text&gt;&lt;/th&gt;
            &lt;th&gt;&lt;text&gt;Code&lt;/text&gt;&lt;/th&gt;
            &lt;th&gt;&lt;text&gt;Restored image&lt;/text&gt;&lt;/th&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;
                &lt;div class="border"&gt;
                    &lt;canvas id="draw"&gt;&lt;/canvas&gt;
                &lt;/div&gt;
            &lt;/td&gt;
            &lt;td&gt;
                &lt;div id="slidecontainer"&gt;
                    &lt;input type="range" min="-5" max="5" value="0" step="0.1" class="slider"&gt;
                &lt;/div&gt;
            &lt;/td&gt;
            &lt;td&gt;
                &lt;div class="border"&gt;
                    &lt;canvas id="restore"&gt;&lt;/canvas&gt;
                &lt;/div&gt;
            &lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;&lt;button type="button" id="draw_clear" onclick="drawClear()"&gt;Clear&lt;/button&gt;&lt;/td&gt;
            &lt;td&gt;
                &lt;span id="encoder_out" style="font-weight: bold;"&gt;(0.0, 0.0)&lt;/span&gt;
            &lt;/td&gt;
            &lt;td&gt;&lt;/td&gt;
        &lt;/tr&gt;
    &lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;Если мы зададим вопрос: за что отвечает каждое значение в коде, то в общем случае ответа не будет. В процессе обучения каждое измерение скрытого вектора начинает отвечать за случайный аспект написания цифры. Это может быть наклон, толщина линии, пропорции, или что-то другое. Это можно определить только экспериментально для уже обученной сети.&lt;/p&gt;
&lt;h1&gt;Генерация данных&lt;/h1&gt;
&lt;p&gt;Используя энкодер мы получили отображение цифр из валидационного набора на пространство кодов.
Каждая точка изображения соответствует двумерному коду.
В следующем примере мы увидим как скрытое двумерное векторное пространство связано с изображением цифры.&lt;/p&gt;
&lt;div class="example" id="example_1"&gt;
    &lt;table class="example" style="width: 100%; height: auto; table-layout: fixed;"&gt;
        &lt;tr&gt;
            &lt;th&gt;&lt;text&gt;Map&lt;/text&gt;&lt;/th&gt;
            &lt;th&gt;Code&lt;/td&gt;
            &lt;th&gt;&lt;text&gt;Generated image&lt;/text&gt;&lt;/th&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;
                &lt;div class="border"&gt;
                    &lt;img src="data/vae/map.png" alt="map" id="map"&gt;
                &lt;/div&gt;
            &lt;/td&gt;
            &lt;td&gt;
                &lt;span id="ex1_code" style="font-weight: bold;"&gt;(0.0, 0.0)&lt;/span&gt;
            &lt;/td&gt;
            &lt;td&gt;
                &lt;div class="border"&gt;
                    &lt;canvas class="canvas elevation" id="viewport"&gt;&lt;/canvas&gt;
                &lt;/div&gt;
            &lt;/td&gt;
        &lt;/tr&gt;
    &lt;/table&gt;
&lt;/div&gt;

&lt;h1&gt;Как и почему оно работает&lt;/h1&gt;
&lt;p&gt;Тут должна быть диаграмма работы вариационного автокодировщика.&lt;/p&gt;
&lt;p&gt;Вариационный автокодировщик состоит из последовательно соединенных нейросетей: кодировщика и декодировщика. И кодировщик и декодировщик являются полносвязными нейросетями (читай многослойный перцептрон - MLP). На вход кодировщику подается исходное изображение рукописной цифры. На выходе кодировщика параметры нормального распределения &lt;span class="math"&gt;\(N(z|\mu(X, \theta), \sigma(X, \theta))\)&lt;/span&gt;. Где &lt;span class="math"&gt;\(\mu\)&lt;/span&gt; и &lt;span class="math"&gt;\(\sigma\)&lt;/span&gt; это функции с обучаемыми параметрами &lt;span class="math"&gt;\(\theta\)&lt;/span&gt;, в нашем случае это нейросеть-кодировщик. Cкрытый вектор семплируется из этого распределения. На вход декодировщику подаюся значения семплированные из указанного ранее нормально граспределения, а на выходе вычисляется восстановленное по скрытому вектору изображение.&lt;/p&gt;
&lt;p&gt;В вариационном автокодировщике скрытый вектор моделируется с помощью многомерного нормального распределения &lt;span class="math"&gt;\(N(\boldsymbol{\mu}, \boldsymbol{\Sigma})\)&lt;/span&gt;. Предполагается, что компоненты скрытого вектора &lt;span class="math"&gt;\(\boldsymbol{z}\)&lt;/span&gt; статистически независимы, следовательно ковариационная матрица &lt;span class="math"&gt;\(\boldsymbol{\Sigma}\)&lt;/span&gt; принимает диагональный вид. В процессе обучения автокодировщик оценивает плотности вероятностей для компонентов скрытого вектора. Другими словами праметры многомерного нормального распределения как функции фходных данных моделируются нейронной сетью. При сжатии на выходе мы получим параметры многомерного нормального распределения - математическое ожидание &lt;span class="math"&gt;\(\mu\)&lt;/span&gt; и дисперсию &lt;span class="math"&gt;\(\sigma\)&lt;/span&gt;.&lt;/p&gt;
&lt;h1&gt;Источники&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1312.6114"&gt;Auto-Encoding Variational Bayes [Diederik P Kingma, Max Welling]&lt;/a&gt; исходная научная работа, в которой впервые был представлен вариационный автокодировщик.&lt;/li&gt;
&lt;/ol&gt;
&lt;script src="data/vae/script_example_1.js"&gt;&lt;/script&gt;
&lt;script src="data/vae/script_example_2.js"&gt;&lt;/script&gt;

&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js','boldsymbol.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="Machine Learning"></category><category term="AI"></category><category term="ML"></category><category term="VAE"></category><category term="example"></category></entry></feed>